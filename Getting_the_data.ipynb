{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Getting the data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5QamIiPvxNf"
      },
      "source": [
        "# Getting tweets from Twitter API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouEfxaQL2kI_"
      },
      "source": [
        "This fists part contains a lot of code from [Twitter API Notebook](https://github.com/ivanovitchm/network_analysis/blob/main/week_08/Twitter.ipynb) from [Network Analysis Class](https://github.com/ivanovitchm/network_analysis) by [Ivanovitch Silva](https://github.com/ivanovitchm)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLj91JLptwBk"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsIQPpX3voVb",
        "outputId": "f6d536bf-e542-4060-a2ad-e5b7bb50f64a"
      },
      "source": [
        "!pip install Twython"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Twython\n",
            "  Downloading twython-3.9.1-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from Twython) (1.3.0)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from Twython) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->Twython) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->Twython) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->Twython) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->Twython) (2021.5.30)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.4.0->Twython) (3.1.1)\n",
            "Installing collected packages: Twython\n",
            "Successfully installed Twython-3.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRJBrGCdwCfX"
      },
      "source": [
        "from twython import Twython, TwythonError\n",
        "from pprint import pprint\n",
        "import itertools\n",
        "import json\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vC7Qs7mwKxS"
      },
      "source": [
        "## Twitter API Authentication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyLOrVNNKUhc"
      },
      "source": [
        "\n",
        "In order to authenticate with Twitter, we'll provide the app details and  ask for a one-time authorization URL to authenticate your user with this app.\n",
        "\n",
        "Copy and paste the API key and secret from your Twitter app into a file named <font color=\"red\">keys.txt</font>. The first line is the API_KEY and the second line of the file is API_SECRET_KEY. For example, a template for the <font color=\"red\">keys.txt</font>: \n",
        "\n",
        "```python\n",
        "df6cf09894907b92f3ea749ef\n",
        "d19c40cbb184f72055c806f107b5158d023a43eb7d8921a0d0\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7DHu4OIwE2m"
      },
      "source": [
        "# open the keys file\n",
        "my_file = open(\"keys.txt\", \"r\")\n",
        "\n",
        "# read the raw data\n",
        "content = my_file.read()\n",
        "\n",
        "# split all lines by  newline character\n",
        "API_KEY, API_SECRET_KEY = content.split(\"\\n\")\n",
        "\n",
        "# close the file\n",
        "my_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pII9dPQdKXg-"
      },
      "source": [
        "Executing the cell should then print out a clickable URL. This link is unique and will work **exactly** once. <font color=\"red\"> Visit this URL, log into Twitter, and then copy the verifier pin that is given to you so as to paste it in the next step</font>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H_l7zB8wHNv",
        "outputId": "e9df8980-a80d-4ed5-e66f-4b9bae55ee55"
      },
      "source": [
        "twitter = Twython(API_KEY, API_SECRET_KEY)\n",
        "\n",
        "authentication_tokens = twitter.get_authentication_tokens()\n",
        "print(authentication_tokens['auth_url'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://api.twitter.com/oauth/authenticate?oauth_token=1VRgxQAAAAABTaK-AAABe9vC6Rg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEkptfBEKdva"
      },
      "source": [
        "\n",
        "That verifier PIN goes into the next cell. This will be different every time you run these steps. The `authentication_tokens` include temporary tokens that go with this verifier PIN; by submitting these together, we show Twitter that we are who we say we are."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZnFYXKkwN1O"
      },
      "source": [
        "# Replace the verifier with the pin number obtained with your web browser in the previous step\n",
        "VERIFIER = '8289025'\n",
        "\n",
        "twitter = Twython(API_KEY, API_SECRET_KEY,\n",
        "                  authentication_tokens['oauth_token'],\n",
        "                  authentication_tokens['oauth_token_secret'])\n",
        "\n",
        "authorized_tokens = twitter.get_authorized_tokens(VERIFIER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2fcO2xIw5-8"
      },
      "source": [
        "twitter = Twython(API_KEY, API_SECRET_KEY,\n",
        "                  authorized_tokens['oauth_token'],\n",
        "                  authorized_tokens['oauth_token_secret'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMsThTErxIbM"
      },
      "source": [
        "## Get argentinian tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8x-3z_nwmAc",
        "outputId": "b4b5314d-dd03-4ff9-99a8-b25d4dbb9ecc"
      },
      "source": [
        "assert twitter.get_application_rate_limit_status()['resources'][\"search\"]['/search/tweets']['remaining'] >= 180, \"To continue, you must have at least 180 requisitions remaining.\"\n",
        "\n",
        "params = {\n",
        "\t'q': 'brasil argentina',\n",
        "\t'lang': 'es',\n",
        "\t'result_type': None,\n",
        "\t'until': '2021-09-06',\n",
        "    'count': 100\n",
        "}\n",
        "\n",
        "#\n",
        "# Get recent tweets\n",
        "#\n",
        "NUM_TWEETS_TO_FETCH = 14000\n",
        "params['result_type'] = 'recent'\n",
        "\n",
        "cursor = twitter.cursor(twitter.search, **params)\n",
        "search_tweets = list(itertools.islice(cursor, NUM_TWEETS_TO_FETCH))\n",
        "print('recents:', len(search_tweets))\n",
        "\n",
        "#\n",
        "# Get mixed tweets\n",
        "#\n",
        "NUM_TWEETS_TO_FETCH = 3000\n",
        "params['result_type'] = 'mixed'\n",
        "\n",
        "cursor = twitter.cursor(twitter.search, **params)\n",
        "search_tweets.extend(list(itertools.islice(cursor, NUM_TWEETS_TO_FETCH)))\n",
        "print('recent + mixed:', len(search_tweets))\n",
        "\n",
        "#\n",
        "# Get popular tweets\n",
        "#\n",
        "NUM_TWEETS_TO_FETCH = 100\n",
        "params['result_type'] = 'popular'\n",
        "\n",
        "cursor = twitter.cursor(twitter.search, **params)\n",
        "search_tweets.extend(list(itertools.islice(cursor, NUM_TWEETS_TO_FETCH)))\n",
        "print('recents + mixed + popular:', len(search_tweets))\n",
        "\n",
        "print('Saving...')\n",
        "with open(f'argentinian_rawdata.json', 'w') as fp:\n",
        "    json.dump(search_tweets, fp,  indent=4)\n",
        "print('Saved!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recents: 14000\n",
            "recent + mixed: 17000\n",
            "recents + mixed + popular: 17030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwazOSKv7tnN"
      },
      "source": [
        "# Sleep for 15min to renew remaining requisitions\n",
        "time.sleep(901)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln8_Y-taxNTx"
      },
      "source": [
        "## Get brazilian tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hsq5eDK-GAKj",
        "outputId": "ea3c1601-9239-4fef-8752-af4dcab57f14"
      },
      "source": [
        "assert twitter.get_application_rate_limit_status()['resources'][\"search\"]['/search/tweets']['remaining'] >= 180, \"To continue, you must have at least 180 requisitions remaining.\"\n",
        "\n",
        "params = {\n",
        "\t'q': 'brasil argentina',\n",
        "\t'lang': 'pt',\n",
        "\t'result_type': None,\n",
        "\t'until': '2021-09-06',\n",
        "    'count': 100\n",
        "}\n",
        "\n",
        "#\n",
        "# Get recent tweets\n",
        "#\n",
        "NUM_TWEETS_TO_FETCH = 14000\n",
        "params['result_type'] = 'recent'\n",
        "\n",
        "cursor = twitter.cursor(twitter.search, **params)\n",
        "search_tweets = list(itertools.islice(cursor, NUM_TWEETS_TO_FETCH))\n",
        "print('recents:', len(search_tweets))\n",
        "\n",
        "#\n",
        "# Get mixed tweets\n",
        "#\n",
        "NUM_TWEETS_TO_FETCH = 3000\n",
        "params['result_type'] = 'mixed'\n",
        "\n",
        "cursor = twitter.cursor(twitter.search, **params)\n",
        "search_tweets.extend(list(itertools.islice(cursor, NUM_TWEETS_TO_FETCH)))\n",
        "print('recent + mixed:', len(search_tweets))\n",
        "\n",
        "#\n",
        "# Get popular tweets\n",
        "#\n",
        "NUM_TWEETS_TO_FETCH = 100\n",
        "params['result_type'] = 'popular'\n",
        "\n",
        "cursor = twitter.cursor(twitter.search, **params)\n",
        "search_tweets.extend(list(itertools.islice(cursor, NUM_TWEETS_TO_FETCH)))\n",
        "print('recents + mixed + popular:', len(search_tweets))\n",
        "\n",
        "print('Saving...')\n",
        "with open(f'brazilian_rawdata.json', 'w') as fp:\n",
        "    json.dump(search_tweets, fp,  indent=4)\n",
        "print('Saved!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recents: 14000\n",
            "recent + mixed: 17000\n",
            "recents + mixed + popular: 17029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b23HxO6PwD8"
      },
      "source": [
        "# Creating dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLLvTWCc4wre"
      },
      "source": [
        "Here, we're gonna get the rawdata and turn it into a dataframe (csv file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPy_beYM0Xtv"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UviJ1ZUIRIHv"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "import json\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoZ-t4NF1Y33"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOIbhsFhI4YW",
        "outputId": "08797218-a2d2-4821-8f68-74ae8314be4e"
      },
      "source": [
        "!wget https://github.com/matheusmas132/Retweets-Network-Analysis/raw/main/data/brazilian_rawdata.json\n",
        "!wget https://github.com/matheusmas132/Retweets-Network-Analysis/raw/main/data/argentinian_rawdata.json"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-15 01:48:33--  https://github.com/matheusmas132/Retweets-Network-Analysis/raw/main/data/brazilian_rawdata.json\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/matheusmas132/Retweets-Network-Analysis/main/data/brazilian_rawdata.json [following]\n",
            "--2021-09-15 01:48:33--  https://raw.githubusercontent.com/matheusmas132/Retweets-Network-Analysis/main/data/brazilian_rawdata.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94189695 (90M) [text/plain]\n",
            "Saving to: ‘brazilian_rawdata.json.1’\n",
            "\n",
            "brazilian_rawdata.j 100%[===================>]  89.83M   191MB/s    in 0.5s    \n",
            "\n",
            "2021-09-15 01:48:34 (191 MB/s) - ‘brazilian_rawdata.json.1’ saved [94189695/94189695]\n",
            "\n",
            "--2021-09-15 01:48:34--  https://github.com/matheusmas132/Retweets-Network-Analysis/raw/main/data/argentinian_rawdata.json\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/matheusmas132/Retweets-Network-Analysis/main/data/argentinian_rawdata.json [following]\n",
            "--2021-09-15 01:48:34--  https://raw.githubusercontent.com/matheusmas132/Retweets-Network-Analysis/main/data/argentinian_rawdata.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 93403887 (89M) [text/plain]\n",
            "Saving to: ‘argentinian_rawdata.json’\n",
            "\n",
            "argentinian_rawdata 100%[===================>]  89.08M   153MB/s    in 0.6s    \n",
            "\n",
            "2021-09-15 01:48:35 (153 MB/s) - ‘argentinian_rawdata.json’ saved [93403887/93403887]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH0GvpW5P7Gs"
      },
      "source": [
        "with open('argentinian_rawdata.json') as json_file:\n",
        "    argentinian_raw = pd.DataFrame(json.load(json_file))\n",
        "\n",
        "with open('brazilian_rawdata.json') as json_file:\n",
        "    brazilian_raw = pd.DataFrame(json.load(json_file))"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLyVrdst1c1p"
      },
      "source": [
        "## Filter columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkdOAKQwX7zN"
      },
      "source": [
        "# Get a full dataframe and return the same with\n",
        "# filtered user data.\n",
        "def get_user_data(df):\n",
        "    user_info = pd.DataFrame(dict(df.user)).T\n",
        "\n",
        "    df['user_id_str'] = user_info['id_str']\n",
        "    df['user_name'] = user_info['name']\n",
        "    df['user_screen_name'] = user_info['screen_name']\n",
        "    df['user_location'] = user_info['location']\n",
        "    df['is_verified_user'] = user_info['verified']\n",
        "    df['user_followers_count'] = user_info['followers_count']\n",
        "    df['user_friends_count'] = user_info['friends_count']\n",
        "\n",
        "    df = df.drop(columns=['user'])\n",
        "\n",
        "    return df\n",
        "\n",
        "# Get a full dataframe and return the same with\n",
        "# filtered retweeted tweet data.\n",
        "def get_retweeted_data(df):\n",
        "    retweet_info = pd.DataFrame(dict(df.retweeted_status)).T\n",
        "\n",
        "    df['retweeted_created_at'] = retweet_info['created_at']\n",
        "    df['retweeted_id_str'] = retweet_info['id_str']\n",
        "    df['retweeted_text'] = retweet_info['text']\n",
        "    df['retweeted_truncated'] = retweet_info['truncated']\n",
        "    df['retweeted_user_id_str'] = retweet_info['user'].apply(lambda x: str(dict(x)['id_str']) if type(x) == dict else x)\n",
        "    df['retweeted_user_name'] = retweet_info['user'].apply(lambda x: str(dict(x)['name']) if type(x) == dict else x)\n",
        "    df['retweeted_user_screen_name'] = retweet_info['user'].apply(lambda x: str(dict(x)['screen_name']) if type(x) == dict else x)\n",
        "    df['retweeted_user_location'] = retweet_info['user'].apply(lambda x: str(dict(x)['location']) if type(x) == dict else x)\n",
        "    df['retweeted_is_verified_user'] = retweet_info['user'].apply(lambda x: str(dict(x)['verified']) if type(x) == dict else x)\n",
        "    df['retweeted_user_followers_count'] = retweet_info['user'].apply(lambda x: str(dict(x)['followers_count']) if type(x) == dict else x)\n",
        "    df['retweeted_user_friends_count'] = retweet_info['user'].apply(lambda x: str(dict(x)['friends_count']) if type(x) == dict else x)\n",
        "    df['retweeted_is_quote_status'] = retweet_info['is_quote_status']\n",
        "    df['retweeted_retweet_count'] = retweet_info['retweet_count']\n",
        "    df['retweeted_favorite_count'] = retweet_info['favorite_count']\n",
        "\n",
        "    df = df.drop(columns=['retweeted_status'])\n",
        "\n",
        "    return df\n",
        "\n",
        "# Get a full dataframe with raw tweets data and\n",
        "# return filtered data.\n",
        "def filter_columns(df):\n",
        "    columns = ['created_at', 'id_str', 'text', 'truncated', 'user',\n",
        "               'retweeted_status', 'is_quote_status', 'retweet_count',\n",
        "               'favorite_count']\n",
        "    df = df[columns]\n",
        "\n",
        "    df = get_user_data(df)\n",
        "    df = get_retweeted_data(df)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Filter the data for each dataset\n",
        "argentinian = filter_columns(argentinian_raw)\n",
        "brazilian = filter_columns(brazilian_raw)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MH6Vge0JoVt"
      },
      "source": [
        "## Remove duplicates and add untracked tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIkn7TVBAnBN",
        "outputId": "e10004e4-cf66-45ec-84e4-43f57dfd7e54"
      },
      "source": [
        "ar_size = argentinian.shape[0]\n",
        "br_size = brazilian.shape[0]\n",
        "\n",
        "# Remove duplicates\n",
        "argentinian.drop_duplicates(subset=['id_str'], inplace=True, ignore_index=True)\n",
        "brazilian.drop_duplicates(subset=['id_str'], inplace=True, ignore_index=True)\n",
        "\n",
        "print(f'Argentine: {ar_size - argentinian.shape[0]} rows was dropped after remove duplicates')\n",
        "print(f'Brazil: {br_size - brazilian.shape[0]} rows was dropped after remove duplicates')"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Argentine: 103 rows was dropped after remove duplicates\n",
            "Brazil: 103 rows was dropped after remove duplicates\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auYqChtoCvXM",
        "outputId": "52839e1b-e720-4d81-f8f5-50784e732903"
      },
      "source": [
        "# Add to a given DataFrame untracked tweets, that is, tweets \n",
        "# that appeared as retweeted but weren’t in the main data.\n",
        "def get_untracked_tweets(df):\n",
        "    # Get rows with untracked tweets\n",
        "    tracked_tweets = list(df['id_str'].values)\n",
        "    non_tracked = df[(df['retweeted_id_str'].notna()) & (~df['retweeted_id_str'].isin(tracked_tweets))]\n",
        "\n",
        "    retweeted_columns = ['retweeted_created_at', 'retweeted_id_str', 'retweeted_text', 'retweeted_truncated',\n",
        "                         'retweeted_is_quote_status', 'retweeted_retweet_count', 'retweeted_favorite_count',\n",
        "                         'retweeted_user_id_str', 'retweeted_user_name', 'retweeted_user_screen_name',\n",
        "                         'retweeted_user_location', 'retweeted_is_verified_user', 'retweeted_user_followers_count',\n",
        "                         'retweeted_user_friends_count']\n",
        "    new_tweets = non_tracked[retweeted_columns]\n",
        "\n",
        "    new_tweets = new_tweets.rename(columns={column:column.replace('retweeted_', '') for column in retweeted_columns})\n",
        "\n",
        "    # Drop duplicated tweets\n",
        "    new_tweets.drop_duplicates(subset=['id_str'], inplace=True, ignore_index=True)\n",
        "\n",
        "    # Add untracked tweets to the main dataframe\n",
        "    df = df.append(new_tweets, ignore_index=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "ar_size = argentinian.shape[0]\n",
        "br_size = brazilian.shape[0]\n",
        "\n",
        "argentinian = get_untracked_tweets(argentinian)\n",
        "brazilian = get_untracked_tweets(brazilian)\n",
        "\n",
        "print(f'Argentine: {argentinian.shape[0] - ar_size} untracked tweets added')\n",
        "print(f'Brazil: {brazilian.shape[0] - br_size} untracked tweets added')"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Argentine: 1490 untracked tweets added\n",
            "Brazil: 761 untracked tweets added\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAnM22KjJxZq"
      },
      "source": [
        "## Export csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt03jjDaMWN1"
      },
      "source": [
        "argentinian.to_excel('argentinian.xlsx', index=False)\n",
        "brazilian.to_excel('brazilian.xlsx', index=False)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7pjo7YP0fPW"
      },
      "source": [
        "# Creating network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIOs7dEH4-SI"
      },
      "source": [
        "Now, we're gonna turn the dataframe into a network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQTJuOvXW-5S"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR72MZso0khR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a61670e-b7a1-4c9c-b815-4734d719fcee"
      },
      "source": [
        "!pip install networkx==2.6.2"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: networkx==2.6.2 in /usr/local/lib/python3.7/dist-packages (2.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTjfhnDXXPlO"
      },
      "source": [
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pprint import pprint"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBRpoa6oXRCY"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OgVbq2_aBVf",
        "outputId": "f884dfc8-731b-4955-92ab-681d845a1da4"
      },
      "source": [
        "!wget https://github.com/matheusmas132/Retweets-Network-Analysis/raw/main/data/argentinian.xlsx\n",
        "!wget https://github.com/matheusmas132/Retweets-Network-Analysis/raw/main/data/brazilian.xlsx"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-15 03:02:46--  https://github.com/matheusmas132/Retweets-Network-Analysis/raw/main/data/argentinian.xlsx\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/matheusmas132/Retweets-Network-Analysis/main/data/argentinian.xlsx [following]\n",
            "--2021-09-15 03:02:46--  https://raw.githubusercontent.com/matheusmas132/Retweets-Network-Analysis/main/data/argentinian.xlsx\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3162978 (3.0M) [application/octet-stream]\n",
            "Saving to: ‘argentinian.xlsx.1’\n",
            "\n",
            "argentinian.xlsx.1  100%[===================>]   3.02M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-09-15 03:02:46 (165 MB/s) - ‘argentinian.xlsx.1’ saved [3162978/3162978]\n",
            "\n",
            "--2021-09-15 03:02:47--  https://github.com/matheusmas132/Retweets-Network-Analysis/raw/main/data/brazilian.xlsx\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/matheusmas132/Retweets-Network-Analysis/main/data/brazilian.xlsx [following]\n",
            "--2021-09-15 03:02:47--  https://raw.githubusercontent.com/matheusmas132/Retweets-Network-Analysis/main/data/brazilian.xlsx\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2961794 (2.8M) [application/octet-stream]\n",
            "Saving to: ‘brazilian.xlsx.1’\n",
            "\n",
            "brazilian.xlsx.1    100%[===================>]   2.82M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-09-15 03:02:47 (128 MB/s) - ‘brazilian.xlsx.1’ saved [2961794/2961794]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COnGk6hTXUy0"
      },
      "source": [
        "argentinian = pd.read_excel('argentinian.xlsx', converters={'id_str':str,'user_id_str':str,'retweeted_id_str':str, 'retweeted_user_id_str':str})\n",
        "brazilian = pd.read_excel('brazilian.xlsx', converters={'id_str':str,'user_id_str':str,'retweeted_id_str':str, 'retweeted_user_id_str':str})"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7DFuJakXXrK"
      },
      "source": [
        "## Build the networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImuKAdZ7bhhP"
      },
      "source": [
        "# Get the given dataframe rows with retweets\n",
        "def get_retweets_dataframe(df):\n",
        "    return df[df['retweeted_id_str'].notna()]\n",
        "\n",
        "# Add data_columns data to nodes using a dataframe\n",
        "def add_node_data(D, df, id_column, data_columns):\n",
        "    nodes = list(D.nodes)\n",
        "\n",
        "    data_columns.append(id_column)\n",
        "\n",
        "    attrs = df[df[id_column].isin(nodes)].drop_duplicates(subset=[id_column], ignore_index=True)\n",
        "    attrs = attrs[data_columns].set_index(id_column).to_dict('index')\n",
        "\n",
        "    nx.set_node_attributes(D, attrs)\n",
        "\n",
        "    return D\n",
        "\n",
        "# Build a network connecting tweets if there are a retweet relation\n",
        "def build_tweets_network(df):\n",
        "    D = nx.DiGraph()\n",
        "\n",
        "    retweets = get_retweets_dataframe(df)\n",
        "\n",
        "    for index, row in retweets.iterrows():\n",
        "        retweeted_id = row['retweeted_id_str']\n",
        "        retweeter_id = row['id_str']\n",
        "\n",
        "        # Edge direction: retweeted_id -> retweeter_id\n",
        "        if D.has_edge(retweeted_id, retweeter_id):\n",
        "            D.edges[retweeted_id, retweeter_id]['weight'] += 1\n",
        "        else:\n",
        "            D.add_edge(retweeted_id, retweeter_id, weight=1)\n",
        "\n",
        "    D = add_node_data(D, df, 'id_str', ['text', 'truncated', 'is_quote_status', 'retweet_count', 'favorite_count', 'favorite_count'])\n",
        "\n",
        "    return D\n",
        "\n",
        "# Build a network connecting users if one retweeted the other user tweet\n",
        "def build_users_network(df):\n",
        "    D = nx.DiGraph()\n",
        "\n",
        "    retweets = get_retweets_dataframe(df)\n",
        "\n",
        "    # Edge direction: retweeted_sn -> retweeter_sn\n",
        "    for index, row in retweets.iterrows():\n",
        "        retweeted_sn = row['retweeted_user_screen_name']\n",
        "        retweeter_sn = row['user_screen_name']\n",
        "\n",
        "        if D.has_edge(retweeted_sn, retweeter_sn):\n",
        "            D.edges[retweeted_sn, retweeter_sn]['weight'] += 1\n",
        "        else:\n",
        "            D.add_edge(retweeted_sn, retweeter_sn, weight=1)\n",
        "\n",
        "    D = add_node_data(D, df, 'user_screen_name', ['user_id_str', 'user_name', 'user_location', 'is_verified_user', 'user_followers_count', 'user_friends_count'])\n",
        "\n",
        "    return D\n",
        "\n",
        "argentinian_tweets_net = build_tweets_network(argentinian)\n",
        "brazilian_tweets_net = build_tweets_network(brazilian)\n",
        "\n",
        "argentinian_users_net = build_users_network(argentinian)\n",
        "brazilian_users_net = build_users_network(brazilian)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-oey2fsXanT"
      },
      "source": [
        "## Export networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtpxWUmeXcvi"
      },
      "source": [
        "nx.write_graphml(argentinian_tweets_net, \"argentinian_tweets_net.graphml\")\n",
        "nx.write_graphml(brazilian_tweets_net, \"brazilian_tweets_net.graphml\")\n",
        "\n",
        "nx.write_graphml(argentinian_users_net, \"argentinian_users_net.graphml\")\n",
        "nx.write_graphml(brazilian_users_net, \"brazilian_users_net.graphml\")"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uWqZuMSnmcq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}